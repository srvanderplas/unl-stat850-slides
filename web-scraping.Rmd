---
title: "Web Scraping"
subtitle: "Scraping Cats off the Internet"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "template/unl.css"]
    includes:
      in_header: template/header.html
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
```{r setup, include=FALSE, message=FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, dpi= 300)
options(width=60)
library(tidyverse)
```



## Web Scraping 

- Transform data from web pages into usable information

- Automate the process

- Use data cleaning tools to get the data into a format suitable for statistical analysis/visualization


---

## `rvest` + `xml2`: Easy Web Scraping
  
- `read_html` gets the full set of HTML markup from a URL

```{r warning = FALSE, message = FALSE}
library(rvest)
library(xml2)
url <- "https://www.catbreedslist.com/all-cat-breeds/american-shorthair.html"
html <- read_html(url)
html
```

- Use `html_attr`, `html_node`, `html_table`, and `html_text` to extract useful information from the markup

---

## HTML Structure

- HTML and XML are markup languages which use a series of tags: 

    <tagname, tag-attribute1 = '...'> tag-value </tagname>

- We can parse HTML by carefully selecting the right tag names and attributes 

- This requires examining the HTML directly in most cases


---

## SelectorGadget

- SelectorGadget is a javascript bookmarklet to determine the css selectors of pieces of a website we want to extract.

- Bookmark the [SelectorGadget](https://rvest.tidyverse.org/articles/selectorgadget.html) link, then click on it to use it (or add the chrome extension)

- When SelectorGadget is active, pieces of the website are highlighted in orange/green/red.

- Use SelectorGadget on https://www.catbreedslist.com/cat-breeds-a-z/ .
    - Can you find a selector that will get you a link to each cat's information page?

If you prefer, you can also read the HTML code and create your own [CSS](https://www.w3schools.com/cssref/css_selectors.asp) or [XPATH](https://www.w3schools.com/xml/xpath_syntax.asp) selectors. 
(This is what I do usually -- it's a bit more precise)


---
class:inverse
## Our Turn

Use Selector Gadget to get the links to each cat's information page.

Hint: Links are indicated with an `<a href="url">Link text</a>` structure

Bonus: Use `purrr` - it's perfect for this!

```{r include = T}
all_breeds <- "https://www.catbreedslist.com/cat-breeds-a-z/"

cat_info_links <- all_breeds %>%
  read_html() %>%
  # Add an a to the SelectorGadget CSS search
  html_elements(css = ".all-a-z dd a") %>%
  # Use xml_attr to get the href parameter
  map_chr(xml_attr, attr = "href")
```

---
## What do we do now?

- We have a list of structured web pages that contain the same information (we hope)

- Can we systematically pull all of the information out?


---
## Reading Cat Information

```{r}
# Let's make a tibble:
cat_breeds <- tibble(url = cat_info_links) %>%
  # Make the link valid by adding the front part
  mutate(url = paste0("http://catbreedslist.com", url)) %>%
  # Read each page in
  mutate(page = map(url, read_html))

cat_breeds[1,]
```

---
## Reading Cat Names

```{r}
cat_breeds <- cat_breeds %>%
  mutate(name = map(page, html_element, ".content h1") %>% 
           map_chr(html_text))

```

---
## Cat Images

```{r}
# Start at the top of the page with the images
cat_breeds <- cat_breeds %>%
  # Get all images on the page in slides
  mutate(images = map(page, html_elements, ".slideshow .Slides img")) %>%
  # Pull out each image's src link
  mutate(img_src = images %>%
           # Since each page has multiple images,
           # we need nested map statements... eww
           map(.f = ~map_chr(., xml_attr, "src")))

cat_breeds$img_src[[1]]
```

---
## Breed Info

```{r}
cat_breeds <- cat_breeds %>%
  mutate(breed_info = map(page, html_element, css = ".table-01"))

# Check to make sure each page has a table
# View(cat_breeds)

cat_breeds_info <- cat_breeds %>%
  filter(map_int(breed_info, length) > 0) %>%
  mutate(breed_info = map(breed_info, html_table))

cat_breeds_info$breed_info[[1]]
```

---
class: inverse
## Your Turn - Breed Characteristics

See if you can read in the information from the Breed characteristics table!

---
class: inverse
## Your Turn - Breed Characteristics Solution
```{r}

cat_breeds_info <- cat_breeds %>% 
  mutate(characteristics = map(page, html_element, css = ".table-02")) %>%
  filter(map_int(characteristics, length) > 0) %>%
  mutate(characteristics = map(characteristics, html_table))
```
